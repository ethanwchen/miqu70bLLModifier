# miqu70bLLModifier

Using LlamaEdge to run LLM inference:

bash <(curl -sSfL 'https://code.flows.network/webhook/iwYN1SdN3AmPgR5ao5Gt/run-llm.sh')

Downloading the Miqu-70b model, we run it on LlamaEdge to create an LLM app that compiles to Wasm.
